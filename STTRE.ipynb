{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QuNLaZnuwFxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class Uber(Dataset):\n",
        "    def __init__(self, dir, seq_len=60):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, [0,1,2,3,4]])\n",
        "        self.y = data[:, [2]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nJ26KwwvaHnr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class IstanbulStock(Dataset):\n",
        "    def __init__(self, dir, seq_len=40):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7]])\n",
        "        self.y = data[:, [0]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wdsfkmm8F4Ri"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class AirQuality(Dataset):\n",
        "    def __init__(self, dir, seq_len=24):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7,8,9,10,11]])\n",
        "        self.y = data[:, [4]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WmzqDct4x2Nd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class Traffic(Dataset):\n",
        "    def __init__(self, dir, seq_len=24):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, [0,1,2,3,4,5,6,7]])\n",
        "        self.y = data[:, [7]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "brWb5KsPzn42"
      },
      "outputs": [],
      "source": [
        "class AppliancesEnergy1(Dataset):\n",
        "    def __init__(self, dir, seq_len=144):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, 0:26])\n",
        "        self.y = data[:, [0]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dMiQJitnVlSN"
      },
      "outputs": [],
      "source": [
        "class AppliancesEnergy2(Dataset):\n",
        "    def __init__(self, dir, seq_len=144):\n",
        "        self.seq_len = seq_len\n",
        "        data = np.loadtxt(dir, delimiter=',', skiprows=1, dtype=None)\n",
        "        self.X = self.normalize(data[:, 0:26])\n",
        "        self.y = data[:, [1]]\n",
        "        self.num_labels = len(np.unique(self.y))\n",
        "        self.len = len(self.y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.len - self.seq_len)-1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = np.transpose(self.X[idx:idx+self.seq_len])\n",
        "        label = self.y[idx+self.seq_len+1]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "    def normalize(self, X):\n",
        "        X = np.transpose(X)\n",
        "        X_norm = []\n",
        "        for x in X:\n",
        "            x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
        "            X_norm.append(x)\n",
        "        return np.transpose(X_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PFhUi5YX2PGG"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads, seq_len, module, rel_emb):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.device = 'cuda'\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.seq_len = seq_len\n",
        "        self.module = module\n",
        "        self.rel_emb = rel_emb\n",
        "        modules = ['spatial', 'temporal', 'spatiotemporal', 'output']\n",
        "        assert (modules.__contains__(module)), \"Invalid module\"\n",
        "\n",
        "\n",
        "        if module == 'spatial' or module == 'temporal':\n",
        "            self.head_dim = seq_len\n",
        "            self.values = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32)\n",
        "            self.keys = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32, device=self.device)\n",
        "            self.queries = nn.Linear(self.embed_size, self.embed_size, dtype=torch.float32, device=self.device)\n",
        "\n",
        "            if rel_emb:\n",
        "                self.E = nn.Parameter(torch.randn([self.heads, self.head_dim, self.embed_size], device=self.device))\n",
        "\n",
        "\n",
        "        else:\n",
        "            self.head_dim = embed_size // heads\n",
        "            assert (self.head_dim * heads == embed_size), \"Embed size not div by heads\"\n",
        "            self.values = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32)\n",
        "            self.keys = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32, device=self.device)\n",
        "            self.queries = nn.Linear(self.head_dim, self.head_dim, dtype=torch.float32, device=self.device)\n",
        "\n",
        "            if rel_emb:\n",
        "                self.E = nn.Parameter(torch.randn([1, self.seq_len, self.head_dim], device=self.device))\n",
        "\n",
        "        self.fc_out = nn.Linear(self.embed_size, self.embed_size, device=self.device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, _, _ = x.shape\n",
        "\n",
        "        #non-shared weights between heads for spatial and temporal modules\n",
        "        if self.module == 'spatial' or self.module == 'temporal':\n",
        "            values = self.values(x)\n",
        "            keys = self.keys(x)\n",
        "            queries = self.queries(x)\n",
        "            values = values.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
        "            keys = keys.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
        "            queries = queries.reshape(N, self.seq_len, self.heads, self.embed_size)\n",
        "\n",
        "        #shared weights between heads for spatio-temporal module\n",
        "        else:\n",
        "            values, keys, queries = x, x, x\n",
        "            values = values.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
        "            keys = keys.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
        "            queries = queries.reshape(N, self.seq_len, self.heads, self.head_dim)\n",
        "            values = self.values(values)\n",
        "            keys = self.keys(keys)\n",
        "            queries = self.queries(queries)\n",
        "\n",
        "\n",
        "        if self.rel_emb:\n",
        "            QE = torch.matmul(queries.transpose(1, 2), self.E.transpose(1,2))\n",
        "            QE = self._mask_positions(QE)\n",
        "            S = self._skew(QE).contiguous().view(N, self.heads, self.seq_len, self.seq_len)\n",
        "            qk = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
        "            mask = torch.triu(torch.ones(1, self.seq_len, self.seq_len, device=self.device),\n",
        "                    1)\n",
        "            if mask is not None:\n",
        "                qk = qk.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "            attention = torch.softmax(qk / (self.embed_size ** (1/2)), dim=3) + S\n",
        "\n",
        "        else:\n",
        "            qk = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
        "            mask = torch.triu(torch.ones(1, self.seq_len, self.seq_len, device=self.device),\n",
        "                    1)\n",
        "            if mask is not None:\n",
        "                qk = qk.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "            attention = torch.softmax(qk / (self.embed_size ** (1/2)), dim=3)\n",
        "\n",
        "        #attention(N x Heads x Q_Len x K_len)\n",
        "        #values(N x V_len x Heads x Head_dim)\n",
        "        #z(N x Q_len x Heads*Head_dim)\n",
        "\n",
        "        if self.module == 'spatial' or self.module == 'temporal':\n",
        "            z = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, self.seq_len*self.heads, self.embed_size)\n",
        "        else:\n",
        "            z = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, self.seq_len, self.heads*self.head_dim)\n",
        "\n",
        "        z = self.fc_out(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "    def _mask_positions(self, qe):\n",
        "        L = qe.shape[-1]\n",
        "        mask = torch.triu(torch.ones(L, L, device=self.device), 1).flip(1)\n",
        "        return qe.masked_fill((mask == 1), 0)\n",
        "\n",
        "    def _skew(self, qe):\n",
        "        #pad a column of zeros on the left\n",
        "        padded_qe = F.pad(qe, [1,0])\n",
        "        s = padded_qe.shape\n",
        "        padded_qe = padded_qe.view(s[0], s[1], s[3], s[2])\n",
        "        #take out first (padded) row\n",
        "        return padded_qe[:,:,1:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h5x_4EVK2Rao"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, seq_len, module, forward_expansion, rel_emb):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttention(embed_size, heads, seq_len, module, rel_emb=rel_emb)\n",
        "\n",
        "        if module == 'spatial' or module == 'temporal':\n",
        "            self.norm1 = nn.BatchNorm1d(seq_len*heads)\n",
        "            self.norm2 = nn.BatchNorm1d(seq_len*heads)\n",
        "        else:\n",
        "            self.norm1 = nn.BatchNorm1d(seq_len)\n",
        "            self.norm2 = nn.BatchNorm1d(seq_len)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention = self.attention(x)\n",
        "        x = self.norm1(attention + x)\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.norm2(forward + x)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RfZxk9vr2URd"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, seq_len, embed_size, num_layers, heads, device,\n",
        "                 forward_expansion, module, output_size=1,\n",
        "                 rel_emb=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.module = module\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        self.rel_emb = rel_emb\n",
        "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "             TransformerBlock(embed_size, heads, seq_len, module, forward_expansion=forward_expansion, rel_emb = rel_emb)\n",
        "             for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            out = layer(x)\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2LWAXNXk2ZJj"
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_shape, output_size,\n",
        "                 embed_size, num_layers, forward_expansion, heads):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "        self.batch_size, self.num_var, self.seq_len = input_shape\n",
        "        self.device = 'cuda'\n",
        "        self.num_elements = self.seq_len*self.num_var\n",
        "        self.embed_size = embed_size\n",
        "        self.element_embedding = nn.Linear(self.seq_len, embed_size*self.seq_len)\n",
        "        self.pos_embedding = nn.Embedding(self.seq_len, embed_size)\n",
        "        self.variable_embedding = nn.Embedding(self.num_var, embed_size)\n",
        "\n",
        "\n",
        "        self.temporal = Encoder(seq_len=self.seq_len,\n",
        "                                embed_size=embed_size,\n",
        "                                num_layers=num_layers,\n",
        "                                heads=self.num_var,\n",
        "                                device=self.device,\n",
        "                                forward_expansion=forward_expansion,\n",
        "                                module='temporal',\n",
        "                                rel_emb=True)\n",
        "\n",
        "        self.spatial = Encoder(seq_len=self.num_var,\n",
        "                               embed_size=embed_size,\n",
        "                               num_layers=num_layers,\n",
        "                               heads=self.seq_len,\n",
        "                               device=self.device,\n",
        "                               forward_expansion=forward_expansion,\n",
        "                               module = 'spatial',\n",
        "                               rel_emb=True)\n",
        "\n",
        "        self.spatiotemporal = Encoder(seq_len=self.seq_len*self.num_var,\n",
        "                                      embed_size=embed_size,\n",
        "                                      num_layers=num_layers,\n",
        "                                      heads=heads,\n",
        "                                      device=self.device,\n",
        "                                      forward_expansion=forward_expansion,\n",
        "                                      module = 'spatiotemporal',\n",
        "                                      rel_emb=True)\n",
        "\n",
        "\n",
        "        # consolidate embedding dimension\n",
        "        self.fc_out1 = nn.Linear(embed_size, embed_size//2)\n",
        "        self.fc_out2 = nn.Linear(embed_size//2, 1)\n",
        "\n",
        "        #prediction\n",
        "        self.out = nn.Linear((self.num_elements*3), output_size)\n",
        "\n",
        "\n",
        "    def forward(self, x, dropout):\n",
        "        batch_size = len(x)\n",
        "\n",
        "        #process/embed input for temporal module\n",
        "        positions = torch.arange(0, self.seq_len).expand(batch_size, self.num_var, self.seq_len).reshape(batch_size, self.num_var * self.seq_len).to(self.device)\n",
        "        x_temporal = self.element_embedding(x).reshape(batch_size, self.num_elements, self.embed_size)\n",
        "        x_temporal = F.dropout(self.pos_embedding(positions) + x_temporal, dropout)\n",
        "\n",
        "        #process/embed input for spatial module\n",
        "        x_spatial = torch.transpose(x, 1, 2).reshape(batch_size, self.num_var, self.seq_len)\n",
        "        vars = torch.arange(0, self.num_var).expand(batch_size, self.seq_len, self.num_var).reshape(batch_size, self.num_var * self.seq_len).to(self.device)\n",
        "        x_spatial = self.element_embedding(x_spatial).reshape(batch_size, self.num_elements, self.embed_size)\n",
        "        x_spatial = F.dropout(self.variable_embedding(vars) + x_spatial, dropout)\n",
        "\n",
        "\n",
        "        #process/embed input for spatio-temporal module\n",
        "        positions = torch.arange(0, self.seq_len).expand(batch_size, self.num_var, self.seq_len).reshape(batch_size, self.num_var* self.seq_len).to(self.device)\n",
        "        x_spatio_temporal = self.element_embedding(x).reshape(batch_size, self.seq_len* self.num_var, self.embed_size)\n",
        "        x_spatio_temporal = F.dropout(self.pos_embedding(positions) + x_spatio_temporal, dropout)\n",
        "\n",
        "\n",
        "\n",
        "        out1 = self.temporal(x_temporal)\n",
        "        out2 = self.spatial(x_spatial)\n",
        "        out3 = self.spatiotemporal(x_spatio_temporal)\n",
        "        out = torch.cat((out1, out2, out3), 1)\n",
        "        out = self.fc_out1(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.fc_out2(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.out(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo9izz8mr2ev"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchmetrics import MeanAbsolutePercentageError, MeanAbsoluteError\n",
        "\n",
        "NUM_EPOCHS = 10000\n",
        "TEST_SPLIT = 0.5\n",
        "\n",
        "def train_test(embed_size, heads, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset):\n",
        "\n",
        "    device = 'cuda'\n",
        "\n",
        "    datasets = ['Uber', 'Traffic', 'AirQuality', 'AppliancesEnergy1', 'AppliancesEnergy2', 'IstanbulStock']\n",
        "    assert (datasets.__contains__(dataset)), \"Invalid dataset\"\n",
        "\n",
        "    #call dataset class\n",
        "    if dataset == 'Uber':\n",
        "        train_data = Uber(dir)\n",
        "    elif dataset == 'Traffic':\n",
        "        train_data = Traffic(dir)\n",
        "    elif dataset == 'AirQuality':\n",
        "        train_data = AirQuality(dir)\n",
        "    elif dataset == 'AppliancesEnergy1':\n",
        "        train_data = AppliancesEnergy1(dir)\n",
        "    elif dataset == 'AppliancesEnergy2':\n",
        "        train_data = AppliancesEnergy2(dir)\n",
        "    elif dataset == 'IstanbulStock':\n",
        "        train_data = IstanbulStock(dir)\n",
        "\n",
        "\n",
        "\n",
        "    #split into train and test\n",
        "    dataset_size = len(train_data)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(TEST_SPLIT * dataset_size))\n",
        "    train_indices, test_indices = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                            sampler=train_sampler)\n",
        "    test_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                                    sampler=test_sampler)\n",
        "\n",
        "\n",
        "\n",
        "    #define loss function, and evaluation metrics\n",
        "    mape = MeanAbsolutePercentageError().to(device)\n",
        "    mae = MeanAbsoluteError().to(device)\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "    inputs, _ = next(iter(train_dataloader))\n",
        "\n",
        "    model = Transformer(inputs.shape, 1, embed_size=embed_size, num_layers=num_layers,\n",
        "                        forward_expansion=forward_expansion, heads=heads).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    val_losses = []\n",
        "    val_mae = []\n",
        "    val_mape = []\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        if epoch >= 5:\n",
        "            print('Epoch: ', epoch)\n",
        "            print('Average mse: ' + str(np.average(val_losses[-5:])))\n",
        "            print('Average mape: ' + str(np.average(val_mape[-5:])))\n",
        "            print('Average mae: ' + str(np.average(val_mae[-5:])))\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        #train loop\n",
        "        for i, data in enumerate(train_dataloader):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs.to(device), dropout)\n",
        "            loss = loss_fn(output, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss = total_loss + loss\n",
        "\n",
        "        total_loss = 0\n",
        "        train_acc = 0\n",
        "        total_mae = 0\n",
        "        total_mape = 0\n",
        "        div = 1\n",
        "\n",
        "        #test loop\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(test_dataloader):\n",
        "                inputs, labels = data\n",
        "                output = model(inputs.to(device), 0)\n",
        "                loss = loss_fn(output, labels.to(device))\n",
        "\n",
        "                total_mae = total_mae + mae(output, labels.to(device))\n",
        "                total_mape = total_mape + mape(output, labels.to(device))\n",
        "                total_loss = total_loss + loss\n",
        "                #div is used when the number of samples in a batch is less\n",
        "                #than the batch size\n",
        "                div = div + (len(inputs)/batch_size)\n",
        "\n",
        "        val_losses.append(total_loss.item()/div)\n",
        "        val_mae.append(total_mae.item()/div)\n",
        "        val_mape.append(total_mape.item()/div)\n",
        "\n",
        "\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Uber Stock\n"
      ],
      "metadata": {
        "id": "yriwM9-WURMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x92oTplm2abW"
      },
      "outputs": [],
      "source": [
        "d = 32\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.0001\n",
        "batch_size = 64\n",
        "dir = ''\n",
        "dataset = 'Uber'\n",
        "\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Appliances Energy 1"
      ],
      "metadata": {
        "id": "jFI5auziUVdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 8\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.0001\n",
        "batch_size = 32\n",
        "dir = ''\n",
        "dataset = 'AppliancesEnergy1'\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ],
      "metadata": {
        "id": "rsdvYYqnUZke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Appliances Energy 2"
      ],
      "metadata": {
        "id": "wD9dlY9BUhV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 8\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.0001\n",
        "batch_size = 32\n",
        "dir = ''\n",
        "dataset = 'AppliancesEnergy2'\n",
        "\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ],
      "metadata": {
        "id": "2swGhmNlUcZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test BeijingPM2.5"
      ],
      "metadata": {
        "id": "uf14C1vDUjJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 32\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.0001\n",
        "batch_size = 256\n",
        "dir = ''\n",
        "dataset = 'AirQuality'\n",
        "\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ],
      "metadata": {
        "id": "nbO8o-HkUteK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Istanbul Stock"
      ],
      "metadata": {
        "id": "wYtjnNFzUt-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 32\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.00005\n",
        "batch_size = 268\n",
        "dir = ''\n",
        "dataset = 'IstanbulStock'\n",
        "\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ],
      "metadata": {
        "id": "W9e0TqtWU0qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Metro Traffic"
      ],
      "metadata": {
        "id": "8OgEMPR2U1K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 32\n",
        "h = 4\n",
        "num_layers = 3\n",
        "forward_expansion = 1\n",
        "dropout = 0.1\n",
        "lr = 0.0001\n",
        "batch_size = 256\n",
        "dir = ''\n",
        "dataset = 'Traffic'\n",
        "\n",
        "train_test(d, h, num_layers, dropout, forward_expansion, lr, batch_size, dir, dataset)"
      ],
      "metadata": {
        "id": "LMMEqxMlU5fg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}